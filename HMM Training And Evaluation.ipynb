{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"GaussianHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
    "      covars_weight=1, init_params='stmc', means_prior=0, means_weight=0,\n",
    "      min_covar=0.001, n_components=10, n_iter=2000, params='stmc',\n",
    "      random_state=None, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
    "      verbose=False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GHMM_train(dataset, states = 4, trials = 10,cov = \"diag\",max_iter=1000, randomSeed = 100, min_cov = 1e-3):\n",
    "    rndNum = 10\n",
    "    prob = -np.inf\n",
    "    best_g = None\n",
    "    score = 0\n",
    "    np.random.seed(randomSeed)\n",
    "    random_state = np.random.random(trials)\n",
    "    for i in range(len(random_state)):\n",
    "        state = int(random_state[i]*1000)\n",
    "        g = hmm.GaussianHMM(n_components=states, covariance_type = cov, n_iter=max_iter, min_covar = min_cov)\n",
    "        #print g.random_state\n",
    "        g.fit(dataset)\n",
    "        score = g.score(dataset)\n",
    "        if score > prob:\n",
    "            prob = score\n",
    "            best_g = copy.deepcopy(g)\n",
    "        #print \"score\",sum(best_g.score(imcN))\n",
    "        #t = best_g.predict(imcN)\n",
    "    return best_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model = GHMM_train(dataset = birds, states = 6, trials = 1,cov = \"full\",max_iter=1000, randomSeed = 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GHMM_evaluate(testset, GMMmodel):\n",
    "    #test set is a list of sets of name-date collections\n",
    "    #GMMmodel is a dictionary of test data\n",
    "    truth = []\n",
    "    pred = []\n",
    "    for dataset in testset:\n",
    "        truth.append(dataset[0])\n",
    "        test_score = -np.inf\n",
    "        pred_name = None\n",
    "        for modelName, model in GMMmodel.items():\n",
    "            score = model.score(dataset[1])\n",
    "            if score > test_score:\n",
    "                test_score = score\n",
    "                pred_name = modelName\n",
    "        pred.append(pred_name)\n",
    "    label = []\n",
    "    for item in truth:\n",
    "        if item not in label:\n",
    "            label.append(item)\n",
    "    matrix = confusion_matrix(truth, pred, labels=label)\n",
    "    print (\"truth: \",truth)\n",
    "    print (\"prediction: \", pred)\n",
    "    print (\"item order in table\", label)\n",
    "    return matrix\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####testing\n",
    "first, training data with 7 dimensions, magnitude and its frequency, and frequencies of 20th, 60th and 80th quantile in magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load in data f\n",
    "trainA = np.load(\"project_data/DataSetWithMAS/BirdATraining.npy\")\n",
    "trainB = np.load(\"project_data/DataSetWithMAS/BirdBTraining.npy\")\n",
    "trainC = np.load(\"project_data/DataSetWithMAS/BirdCTraining.npy\")\n",
    "trainD = np.load(\"project_data/DataSetWithMAS/BirdDTraining.npy\")\n",
    "trainE = np.load(\"project_data/DataSetWithMAS/BirdETraining.npy\")\n",
    "trainF = np.load(\"project_data/DataSetWithMAS/BirdFTraining.npy\")\n",
    "trainG = np.load(\"project_data/DataSetWithMAS/BirdGTraining.npy\")\n",
    "trainH = np.load(\"project_data/DataSetWithMAS/BirdHTraining.npy\")\n",
    "trainset =[('A',trainA),('B',trainB),('C',trainC),('D',trainD),('E',trainE),('F',trainF),('G',trainG),('H',trainH)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelDict = dict()\n",
    "for dataset in trainset:\n",
    "    model = GHMM_train(dataset = dataset[1], states = 15, trials = 1,cov = \"diag\",max_iter=1000, randomSeed = 120, min_cov = 1e-5)\n",
    "    modelDict[dataset[0]] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testA1 = np.load(\"project_data/DataSetWithMAS/TestA09.npy\")\n",
    "testA2 = np.load(\"project_data/DataSetWithMAS/TestA10.npy\")\n",
    "testB = np.load(\"project_data/DataSetWithMAS/TestB05.npy\")\n",
    "testC = np.load(\"project_data/DataSetWithMAS/TestC06.npy\")\n",
    "testD1 = np.load(\"project_data/DataSetWithMAS/TestD09.npy\")\n",
    "testD2 = np.load(\"project_data/DataSetWithMAS/TestD10.npy\")\n",
    "testE1 = np.load(\"project_data/DataSetWithMAS/TestE11.npy\")\n",
    "testE2 = np.load(\"project_data/DataSetWithMAS/TestE12.npy\")\n",
    "testF1 = np.load(\"project_data/DataSetWithMAS/TestF09.npy\")\n",
    "testF2 = np.load(\"project_data/DataSetWithMAS/TestF10.npy\")\n",
    "testG = np.load(\"project_data/DataSetWithMAS/TestG07.npy\")\n",
    "testH1 = np.load(\"project_data/DataSetWithMAS/TestH16.npy\")\n",
    "testH2 = np.load(\"project_data/DataSetWithMAS/TestH17.npy\")\n",
    "testH3 = np.load(\"project_data/DataSetWithMAS/TestH18.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GHMM_evaluate(testset,modelDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#try different settings hidden states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###testing with 2 dimensions, magnitude and its frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [[x[0],x[1]] for x in trainA]\n",
    "b = [[x[0],x[1]] for x in trainB]\n",
    "c = [[x[0],x[1]] for x in trainC]\n",
    "d = [[x[0],x[1]] for x in trainD]\n",
    "e = [[x[0],x[1]] for x in trainE]\n",
    "f = [[x[0],x[1]] for x in trainF]\n",
    "g = [[x[0],x[1]] for x in trainG]\n",
    "h = [[x[0],x[1]] for x in trainH]\n",
    "trainset = [('A',a),('B',b),('C',c),('D',d),('E',e),('F',f),('G',g),('H',h)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelDict = dict()\n",
    "for dataset in trainset:\n",
    "    model = GHMM_train(dataset = dataset[1], states = 15, trials = 1,cov = \"diag\",max_iter=100, randomSeed = 120, min_cov = 1e-5)\n",
    "    modelDict[dataset[0]] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ta1 = [[x[0],x[1]] for x in testA1]\n",
    "ta2 = [[x[0],x[1]] for x in testA2]\n",
    "tb = [[x[0],x[1]] for x in testB]\n",
    "tc = [[x[0],x[1]] for x in testC]\n",
    "td1 = [[x[0],x[1]] for x in testD1]\n",
    "td2 = [[x[0],x[1]] for x in testD2]\n",
    "te1 = [[x[0],x[1]] for x in testE1]\n",
    "te2 = [[x[0],x[1]] for x in testE2]\n",
    "tf1 = [[x[0],x[1]] for x in testF1]\n",
    "tf2 = [[x[0],x[1]] for x in testF2]\n",
    "tg = [[x[0],x[1]] for x in testG]\n",
    "th1 = [[x[0],x[1]] for x in testH1]\n",
    "th2 = [[x[0],x[1]] for x in testH2]\n",
    "th3 = [[x[0],x[1]] for x in testH3]\n",
    "testset = [(\"A\",ta1),(\"A\",ta2),(\"B\",tb),(\"C\",tc),(\"D\",td1),(\"D\",td2),(\"E\",te1),(\"E\",te2),(\"F\",tf1), (\"F\",tf2), (\"G\",tg),(\"H\", th1),(\"H\", th2),(\"H\", th3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth:  ['A', 'A', 'B', 'C', 'D', 'D', 'E', 'E', 'F', 'F', 'G', 'H', 'H', 'H']\n",
      "prediction:  ['A', 'A', 'B', 'C', 'H', 'F', 'E', 'E', 'F', 'H', 'F', 'H', 'H', 'H']\n",
      "item order in table ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 1],\n",
       "       [0, 0, 0, 0, 2, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 3]])"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GHMM_evaluate(testset,modelDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#try different states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#testing with 20 dimensions, pick five peaks in each frame time, for each peak, collect its magnitude and frequency,\n",
    "#and the two frequencies of magnitudes at 80th percentile of the peak value GMM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainA = np.load(\"project_data/DataSetWithMultipeak/BirdATraining.npy\")\n",
    "trainB = np.load(\"project_data/DataSetWithMultipeak/BirdBTraining.npy\")\n",
    "trainC = np.load(\"project_data/DataSetWithMultipeak/BirdCTraining.npy\")\n",
    "trainD = np.load(\"project_data/DataSetWithMultipeak/BirdDTraining.npy\")\n",
    "trainE = np.load(\"project_data/DataSetWithMultipeak/BirdETraining.npy\")\n",
    "trainF = np.load(\"project_data/DataSetWithMultipeak/BirdFTraining.npy\")\n",
    "trainG = np.load(\"project_data/DataSetWithMultipeak/BirdGTraining.npy\")\n",
    "trainH = np.load(\"project_data/DataSetWithMultipeak/BirdHTraining.npy\")\n",
    "trainset =[('A',trainA),('B',trainB),('C',trainC),('D',trainD),('E',trainE),('F',trainF),('G',trainG),('H',trainH)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelDict = dict()\n",
    "for dataset in trainset:\n",
    "    model = GMMHMM_train(dataset = dataset[1], mix = 5, states = 15, trials = 1,cov = \"diag\",max_iter=5, randomSeed = 1024)\n",
    "    modelDict[dataset[0]] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testA1 = np.load(\"project_data/DataSetWithMultipeak/TestA09.npy\")\n",
    "testA2 = np.load(\"project_data/DataSetWithMultipeak/TestA10.npy\")\n",
    "testB1 = np.load(\"project_data/DataSetWithMultipeak/TestB05.npy\")\n",
    "testC1 = np.load(\"project_data/DataSetWithMultipeak/TestC06.npy\")\n",
    "testD1 = np.load(\"project_data/DataSetWithMultipeak/TestD09.npy\")\n",
    "testD2 = np.load(\"project_data/DataSetWithMultipeak/TestD10.npy\")\n",
    "testE1 = np.load(\"project_data/DataSetWithMultipeak/TestE11.npy\")\n",
    "testE2 = np.load(\"project_data/DataSetWithMultipeak/TestE12.npy\")\n",
    "testF1 = np.load(\"project_data/DataSetWithMultipeak/TestF09.npy\")\n",
    "testF2 = np.load(\"project_data/DataSetWithMultipeak/TestF10.npy\")\n",
    "testG1 = np.load(\"project_data/DataSetWithMultipeak/TestG07.npy\")\n",
    "testH1 = np.load(\"project_data/DataSetWithMultipeak/TestH16.npy\")\n",
    "testH2 = np.load(\"project_data/DataSetWithMultipeak/TestH17.npy\")\n",
    "testH3 = np.load(\"project_data/DataSetWithMultipeak/TestH18.npy\")\n",
    "testset = [('A',testA1),('A',testA2),('B',testB1),(\"C\",testC1),(\"D\",testD1),(\"D\",testD2),(\"E\",testE1),(\"E\",testE2),(\"F\",testF1), (\"F\",testF2), (\"G\",testG1),(\"H\", testH1),(\"H\", testH2),(\"H\", testH3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth:  ['A', 'A', 'B', 'C', 'D', 'D', 'E', 'E', 'F', 'F', 'G', 'H', 'H', 'H']\n",
      "prediction:  ['A', 'A', 'B', 'G', 'H', 'F', 'E', 'E', 'F', 'B', 'H', 'F', 'H', 'H']\n",
      "item order in table ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 1],\n",
       "       [0, 0, 0, 0, 2, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 2]])"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GHMM_evaluate(testset,modelDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#####testing with 10 dimensions, pick five peaks in each frame time, magnitude and frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  85.        ,   11.6632142 ,   11.51303269,   11.38571693,\n",
       "         61.        ,    8.29771025,    8.0202668 ,    7.78114792,\n",
       "         68.        ,    7.44013258,    7.38778344,    7.08121227,\n",
       "        121.        ,    6.06926918,    5.63240736,    5.24867266,\n",
       "        103.        ,    5.74161046,    5.64747872,    5.533117  ])"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainA[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [[x[0],x[1],x[4],x[5],x[8],x[9],x[12],x[13],x[16],x[17]] for x in trainA]\n",
    "b = [[x[0],x[1],x[4],x[5],x[8],x[9],x[12],x[13],x[16],x[17]] for x in trainB]\n",
    "c = [[x[0],x[1],x[4],x[5],x[8],x[9],x[12],x[13],x[16],x[17]] for x in trainC]\n",
    "d = [[x[0],x[1],x[4],x[5],x[8],x[9],x[12],x[13],x[16],x[17]] for x in trainD]\n",
    "e = [[x[0],x[1],x[4],x[5],x[8],x[9],x[12],x[13],x[16],x[17]] for x in trainE]\n",
    "f = [[x[0],x[1],x[4],x[5],x[8],x[9],x[12],x[13],x[16],x[17]] for x in trainF]\n",
    "g = [[x[0],x[1],x[4],x[5],x[8],x[9],x[12],x[13],x[16],x[17]] for x in trainG]\n",
    "h = [[x[0],x[1],x[4],x[5],x[8],x[9],x[12],x[13],x[16],x[17]] for x in trainH]\n",
    "trainset = [('A',a),('B',b),('C',c),('D',d),('E',e),('F',f),('G',g),('H',h)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0, 161.34150888612274, 640.0, 20.67457418939124, 652.0, 14.984776583449952, 648.0, 12.679452475689653, 4.0, 12.578563618606053], [0.0, 197.86671283602729, 648.0, 1.7228789905533801, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 199.99933096207931, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 199.41960069274273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 196.91615730004878, 96.0, 2.7200174188596176, 44.0, 2.3718836834777348, 52.0, 2.3647450137082489, 58.0, 2.1432631841638741]]\n"
     ]
    }
   ],
   "source": [
    "print e[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ta1 = [[x[0],x[1],x[4],x[5],x[8],x[9],x[12],x[13],x[16],x[17]] for x in testA1]\n",
    "ta2 = [[x[0],x[1],x[4],x[5],x[8],x[9],x[12],x[13],x[16],x[17]] for x in testA2]\n",
    "tb1 = [[x[0],x[1],x[4],x[5],x[8],x[9],x[12],x[13],x[16],x[17]] for x in testB1]\n",
    "tc1 = [[x[0],x[1],x[4],x[5],x[8],x[9],x[12],x[13],x[16],x[17]] for x in testC1]\n",
    "td1 = [[x[0],x[1],x[4],x[5],x[8],x[9],x[12],x[13],x[16],x[17]] for x in testD1]\n",
    "td2 = [[x[0],x[1],x[4],x[5],x[8],x[9],x[12],x[13],x[16],x[17]] for x in testD2]\n",
    "te1 = [[x[0],x[1],x[4],x[5],x[8],x[9],x[12],x[13],x[16],x[17]] for x in testE1]\n",
    "te2 = [[x[0],x[1],x[4],x[5],x[8],x[9],x[12],x[13],x[16],x[17]] for x in testE2]\n",
    "tf1 = [[x[0],x[1],x[4],x[5],x[8],x[9],x[12],x[13],x[16],x[17]] for x in testF1]\n",
    "tf2 = [[x[0],x[1],x[4],x[5],x[8],x[9],x[12],x[13],x[16],x[17]] for x in testF2]\n",
    "tg1 = [[x[0],x[1],x[4],x[5],x[8],x[9],x[12],x[13],x[16],x[17]] for x in testG1]\n",
    "th1 = [[x[0],x[1],x[4],x[5],x[8],x[9],x[12],x[13],x[16],x[17]] for x in testH1]\n",
    "th2 = [[x[0],x[1],x[4],x[5],x[8],x[9],x[12],x[13],x[16],x[17]] for x in testH2]\n",
    "th3 = [[x[0],x[1],x[4],x[5],x[8],x[9],x[12],x[13],x[16],x[17]] for x in testH3]\n",
    "testset = [(\"A\",ta1),(\"A\",ta2),(\"B\",tb1),(\"C\",tc1),(\"D\",td1),(\"D\",td2),(\"E\",te1),(\"E\",te2),(\"F\",tf1), (\"F\",tf2), (\"G\",tg1),(\"H\", th1),(\"H\", th2),(\"H\", th3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelDict = dict()\n",
    "for dataset in trainset:\n",
    "    model = GMMHMM_train(dataset = dataset[1], mix = 5, states = 15, trials = 1,cov = \"diag\",max_iter=5, randomSeed = 1024)\n",
    "    modelDict[dataset[0]] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': GMMHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "     init_params='stmcw', n_components=15, n_iter=5, n_mix=5,\n",
       "     params='stmcw', random_state=None, startprob_prior=1.0, tol=0.1,\n",
       "     transmat_prior=1.0, verbose=False),\n",
       " 'B': GMMHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "     init_params='stmcw', n_components=15, n_iter=5, n_mix=5,\n",
       "     params='stmcw', random_state=None, startprob_prior=1.0, tol=0.1,\n",
       "     transmat_prior=1.0, verbose=False),\n",
       " 'C': GMMHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "     init_params='stmcw', n_components=15, n_iter=5, n_mix=5,\n",
       "     params='stmcw', random_state=None, startprob_prior=1.0, tol=0.1,\n",
       "     transmat_prior=1.0, verbose=False),\n",
       " 'D': GMMHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "     init_params='stmcw', n_components=15, n_iter=5, n_mix=5,\n",
       "     params='stmcw', random_state=None, startprob_prior=1.0, tol=0.1,\n",
       "     transmat_prior=1.0, verbose=False),\n",
       " 'E': GMMHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "     init_params='stmcw', n_components=15, n_iter=5, n_mix=5,\n",
       "     params='stmcw', random_state=None, startprob_prior=1.0, tol=0.1,\n",
       "     transmat_prior=1.0, verbose=False),\n",
       " 'F': GMMHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "     init_params='stmcw', n_components=15, n_iter=5, n_mix=5,\n",
       "     params='stmcw', random_state=None, startprob_prior=1.0, tol=0.1,\n",
       "     transmat_prior=1.0, verbose=False),\n",
       " 'G': GMMHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "     init_params='stmcw', n_components=15, n_iter=5, n_mix=5,\n",
       "     params='stmcw', random_state=None, startprob_prior=1.0, tol=0.1,\n",
       "     transmat_prior=1.0, verbose=False),\n",
       " 'H': GMMHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "     init_params='stmcw', n_components=15, n_iter=5, n_mix=5,\n",
       "     params='stmcw', random_state=None, startprob_prior=1.0, tol=0.1,\n",
       "     transmat_prior=1.0, verbose=False)}"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = [[x[1],x[2],x[6]] for x in trainA]\n",
    "b = [[x[1],x[2],x[6]] for x in trainB]\n",
    "c = [[x[1],x[2],x[6]] for x in trainC]\n",
    "d = [[x[1],x[2],x[6]] for x in trainD]\n",
    "e = [[x[1],x[2],x[6]] for x in trainE]\n",
    "f = [[x[1],x[2],x[6]] for x in trainF]\n",
    "g = [[x[1],x[2],x[6]] for x in trainG]\n",
    "h = [[x[1],x[2],x[6]] for x in trainH]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = [[x[0],x[1]] for x in trainA]\n",
    "b = [[x[0],x[1]] for x in trainB]\n",
    "c = [[x[0],x[1]] for x in trainC]\n",
    "d = [[x[0],x[1]] for x in trainD]\n",
    "e = [[x[0],x[1]] for x in trainE]\n",
    "f = [[x[0],x[1]] for x in trainF]\n",
    "g = [[x[0],x[1]] for x in trainG]\n",
    "h = [[x[0],x[1]] for x in trainH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainset = [('A',a),('B',b),('C',c),('D',d),('E',e),('F',f),('G',g),('H',h)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainset =[('A',trainA),('B',trainB),('C',trainC),('D',trainD),('E',trainE),('F',trainF),('G',trainG),('H',trainH)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modela = hmm.GaussianHMM(n_components=10, covariance_type=\"diag\", n_iter=2000).fit(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-52166.264746875953"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modela.score(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"testB = np.load(\"project_data/DataSet2/BirdBTesting.npy\")\n",
    "testD1 = np.load(\"project_data/DataSet2/BirdDTesting.npy\")\n",
    "testD2 = np.load(\"project_data/DataSet2/BirdDTesting(2).npy\")\n",
    "testF1 = np.load(\"project_data/DataSet2/BirdFTesting(1).npy\")\n",
    "testF2 = np.load(\"project_data/DataSet2/BirdFTesting(2).npy\")\n",
    "testG = np.load(\"project_data/DataSet2/BirdGTesting.npy\")\n",
    "testH1 = np.load(\"project_data/DataSet2/BirdHTesting(1).npy\")\n",
    "testH2 = np.load(\"project_data/DataSet2/BirdHTesting(2).npy\")\n",
    "testH3 = np.load(\"project_data/DataSet2/BirdHTesting(3).npy\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testA1 = np.load(\"project_data/DataSetWithMAS/TestA09.npy\")\n",
    "testA2 = np.load(\"project_data/DataSetWithMAS/TestA10.npy\")\n",
    "testB = np.load(\"project_data/DataSetWithMAS/TestB05.npy\")\n",
    "testC = np.load(\"project_data/DataSetWithMAS/TestC06.npy\")\n",
    "testD1 = np.load(\"project_data/DataSetWithMAS/TestD09.npy\")\n",
    "testD2 = np.load(\"project_data/DataSetWithMAS/TestD10.npy\")\n",
    "testE1 = np.load(\"project_data/DataSetWithMAS/TestE11.npy\")\n",
    "testE2 = np.load(\"project_data/DataSetWithMAS/TestE12.npy\")\n",
    "testF1 = np.load(\"project_data/DataSetWithMAS/TestF09.npy\")\n",
    "testF2 = np.load(\"project_data/DataSetWithMAS/TestF10.npy\")\n",
    "testG = np.load(\"project_data/DataSetWithMAS/TestG07.npy\")\n",
    "testH1 = np.load(\"project_data/DataSetWithMAS/TestH16.npy\")\n",
    "testH2 = np.load(\"project_data/DataSetWithMAS/TestH17.npy\")\n",
    "testH3 = np.load(\"project_data/DataSetWithMAS/TestH18.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ta1 = [[x[1],x[2],x[6]] for x in testA1]\n",
    "ta2 = [[x[1],x[2],x[6]] for x in testA2]\n",
    "tb = [[x[1],x[2],x[6]] for x in testB]\n",
    "tc = [[x[1],x[2],x[6]] for x in testC]\n",
    "td1 = [[x[1],x[2],x[6]] for x in testD1]\n",
    "td2 = [[x[1],x[2],x[6]] for x in testD2]\n",
    "te1 = [[x[1],x[2],x[6]] for x in testE1]\n",
    "te2 = [[x[1],x[2],x[6]] for x in testE2]\n",
    "tf1 = [[x[1],x[2],x[6]] for x in testF1]\n",
    "tf2 = [[x[1],x[2],x[6]] for x in testF2]\n",
    "tg = [[x[1],x[2],x[6]] for x in testG]\n",
    "th1 = [[x[1],x[2],x[6]] for x in testH1]\n",
    "th2 = [[x[1],x[2],x[6]] for x in testH2]\n",
    "th3 = [[x[1],x[2],x[6]] for x in testH3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ta1 = [[x[0],x[1]] for x in testA1]\n",
    "ta2 = [[x[0],x[1]] for x in testA2]\n",
    "tb = [[x[0],x[1]] for x in testB]\n",
    "tc = [[x[0],x[1]] for x in testC]\n",
    "td1 = [[x[0],x[1]] for x in testD1]\n",
    "td2 = [[x[0],x[1]] for x in testD2]\n",
    "te1 = [[x[0],x[1]] for x in testE1]\n",
    "te2 = [[x[0],x[1]] for x in testE2]\n",
    "tf1 = [[x[0],x[1]] for x in testF1]\n",
    "tf2 = [[x[0],x[1]] for x in testF2]\n",
    "tg = [[x[0],x[1]] for x in testG]\n",
    "th1 = [[x[0],x[1]] for x in testH1]\n",
    "th2 = [[x[0],x[1]] for x in testH2]\n",
    "th3 = [[x[0],x[1]] for x in testH3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testset = [(\"A\",ta1),(\"A\",ta2),(\"B\",tb),(\"C\",tc),(\"D\",td1),(\"D\",td2),(\"E\",te1),(\"E\",te2),(\"F\",tf1), (\"F\",tf2), (\"G\",tg),(\"H\", th1),(\"H\", th2),(\"H\", th3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testset = [(\"A\",testA1),(\"A\",testA2),(\"B\",testB),(\"C\",testC),(\"D\",testD1),(\"D\",testD2),(\"E\",testE1),(\"E\",testE2),(\"F\",testF1), (\"F\",testF2), (\"G\",testG),(\"H\", testH1),(\"H\", testH2),(\"H\", testH3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelDict = dict()\n",
    "for dataset in trainset:\n",
    "    model = GHMM_train(dataset = dataset[1], states = 15, trials = 1,cov = \"diag\",max_iter=1000, randomSeed = 120, min_cov = 1e-5)\n",
    "    modelDict[dataset[0]] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth:  ['A', 'A', 'B', 'C', 'D', 'D', 'E', 'E', 'F', 'F', 'G', 'H', 'H', 'H']\n",
      "prediction:  ['A', 'A', 'B', 'C', 'F', 'G', 'E', 'E', 'F', 'F', 'G', 'H', 'H', 'H']\n",
      "item order in table ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 2, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 2, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 3]])"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GHMM_evaluate(testset,modelDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def inverse_logLike_ratio(testset, GMMmodel):\n",
    "    #test set is a set of name-date collections\n",
    "    #GMMmodel is a dictionary of test data\n",
    "    truth = testset[0]\n",
    "    test_score = []\n",
    "    inverseLLR = dict()\n",
    "    pred_name = []\n",
    "    for modelName, model in GMMmodel.items():\n",
    "        score = model.score(testset[1])\n",
    "        test_score.append(score)\n",
    "        pred_name.append(modelName)\n",
    "    #print test_score\n",
    "    test_score = np.reciprocal(test_score)\n",
    "    #print test_score\n",
    "    for i in range(len(test_score)):\n",
    "        inverseLLR[pred_name[i]] = test_score[i]*1./sum(test_score)\n",
    "    return truth, inverseLLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('A', {'A': 0.31007220090030013, 'C': 0.026053744816223006, 'B': 0.2058311129303112, 'E': 0.13695679729858626, 'D': 0.00050567823371857105, 'G': 0.15834725405188668, 'F': 5.6559393254539184e-08, 'H': 0.16223315520958093})\n",
      "\n",
      "('A', {'A': 0.2714082293134305, 'C': 0.15335308175703516, 'B': 0.10716024277427623, 'E': 0.10119020799291874, 'D': 0.077157068957780628, 'G': 0.14309610621612387, 'F': 1.5680257138322098e-05, 'H': 0.14661938273129657})\n",
      "\n",
      "('B', {'A': 0.086648786148046178, 'C': 0.11517798584170734, 'B': 0.25506715651591477, 'E': 0.1016589360967271, 'D': 0.090879544419188746, 'G': 0.12461072843163774, 'F': 0.10283657995847237, 'H': 0.12312028258830574})\n",
      "\n",
      "('C', {'A': 0.03105732972811091, 'C': 0.24263564159905798, 'B': 0.022904774414175506, 'E': 0.20955387224359159, 'D': 0.081376674636476742, 'G': 0.22406117791888061, 'F': 1.502469762692489e-05, 'H': 0.18839550476207975})\n",
      "\n",
      "('D', {'A': 0.024534626723163769, 'C': 0.21684773103626098, 'B': 0.0062399159534284685, 'E': 0.20995279255105653, 'D': 0.19475059711871742, 'G': 0.1574771842764309, 'F': 0.00014603541573990757, 'H': 0.19005111692520199})\n",
      "\n",
      "('D', {'A': 0.045379010168115845, 'C': 0.14357363349145383, 'B': 0.052215276351296865, 'E': 0.12808740901427917, 'D': 0.16871092614939306, 'G': 0.12822386387123849, 'F': 0.18148369631536065, 'H': 0.15232618463886202})\n",
      "\n",
      "('E', {'A': 0.0022523116322348598, 'C': 0.083160389329810749, 'B': 0.0030796591396210198, 'E': 0.51061933048888775, 'D': 0.078710924321251624, 'G': 0.085905537240435592, 'F': 0.13655469387047281, 'H': 0.09971715397728545})\n",
      "\n",
      "('E', {'A': 0.0033621095773690162, 'C': 0.085835341408983148, 'B': 0.004539528930454618, 'E': 0.44223057150758427, 'D': 0.099024665697234115, 'G': 0.10534916836394824, 'F': 0.15374672518487006, 'H': 0.10591188932955652})\n",
      "\n",
      "('F', {'A': 0.019659441229479997, 'C': 0.15553856128822052, 'B': 0.020687200957236411, 'E': 0.12515218647382284, 'D': 0.17437949561528579, 'G': 0.12888901686425891, 'F': 0.19350203933422555, 'H': 0.18219205823746998})\n",
      "\n",
      "('F', {'A': 0.031917429966102633, 'C': 0.21484403066878974, 'B': 0.041202996085758531, 'E': 0.17287497712143593, 'D': 0.079178936500391525, 'G': 0.19698329934282482, 'F': 1.3113436911024529e-05, 'H': 0.26298521687778564})\n",
      "\n",
      "('G', {'A': 0.043212679876986251, 'C': 0.13754386709595309, 'B': 0.054676811023282215, 'E': 0.11925913287062047, 'D': 0.16682975072864542, 'G': 0.1420162832590823, 'F': 0.16845227258642856, 'H': 0.16800920255900176})\n",
      "\n",
      "('H', {'A': 0.040364543668343494, 'C': 0.18827456748055521, 'B': 0.023505272205008181, 'E': 0.15153834105895109, 'D': 0.16543368739849548, 'G': 0.19467760007971519, 'F': 6.2543009549736247e-05, 'H': 0.23614344509938165})\n",
      "\n",
      "('H', {'A': 0.022356515983968202, 'C': 0.19835161808279758, 'B': 0.0031015101413280422, 'E': 0.14110741061302282, 'D': 0.21082514261750548, 'G': 0.18517676466924196, 'F': 0.0017337735737728256, 'H': 0.23734726431836312})\n",
      "\n",
      "('H', {'A': 0.023337762808861205, 'C': 0.1927393928182666, 'B': 0.011678394250026427, 'E': 0.15213948088208401, 'D': 0.19941024611088576, 'G': 0.18658767582492655, 'F': 0.0095718200389725717, 'H': 0.22453522726597691})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for test in testset:\n",
    "    print inverse_logLike_ratio(test, modelDict)\n",
    "    print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelF = GHMM_train(trainF, states = 6, trials = 1,cov = \"full\",max_iter=1000, randomSeed = 3, min_cov = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelB = GHMM_train(trainB, states = 30, trials = 1,cov = \"\",max_iter=1000, randomSeed = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelG = GHMM_train(trainG, states = 2, trials = 1,cov = \"full\",max_iter=1000, randomSeed = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GMMHMM_train(dataset, mix = 3, states = 4, trials = 10,cov = \"diag\",max_iter=1000, randomSeed = 100):\n",
    "    rndNum = 10\n",
    "    prob = -np.inf\n",
    "    best_g = None\n",
    "    score = 0\n",
    "    np.random.seed(randomSeed)\n",
    "    random_state = np.random.random(trials)\n",
    "    for i in range(len(random_state)):\n",
    "        state = int(random_state[i]*1000)\n",
    "        g = hmm.GMMHMM(n_components=states, n_mix = mix, covariance_type = cov, n_iter=max_iter, tol=0.1)\n",
    "        #print g.random_state\n",
    "        g.fit(dataset)\n",
    "        score = g.score(dataset)\n",
    "        if score > prob:\n",
    "            prob = score\n",
    "            best_g = copy.deepcopy(g)\n",
    "        #print \"score\",sum(best_g.score(imcN))\n",
    "        #t = best_g.predict(imcN)\n",
    "    return best_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelGMM_A = GMMHMM_train(dataset = trainA, mix = 3, states = 4, trials = 1,cov = \"diag\",max_iter=1000, randomSeed = 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelGHMM_A = GHMM_train(dataset=trainA, states = 4, trials = 1,cov = \"diag\",max_iter=1000, randomSeed = 100, min_cov = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__doc__',\n",
       " '__format__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__module__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_accumulate_sufficient_statistics',\n",
       " '_check',\n",
       " '_compute_log_likelihood',\n",
       " '_compute_posteriors',\n",
       " '_decode_map',\n",
       " '_decode_viterbi',\n",
       " '_do_backward_pass',\n",
       " '_do_forward_pass',\n",
       " '_do_mstep',\n",
       " '_do_viterbi_pass',\n",
       " '_generate_sample_from_state',\n",
       " '_get_param_names',\n",
       " '_init',\n",
       " '_initialize_sufficient_statistics',\n",
       " 'algorithm',\n",
       " 'covariance_type',\n",
       " 'covars_prior',\n",
       " 'decode',\n",
       " 'fit',\n",
       " 'get_params',\n",
       " 'gmms_',\n",
       " 'init_params',\n",
       " 'monitor_',\n",
       " 'n_components',\n",
       " 'n_iter',\n",
       " 'n_mix',\n",
       " 'params',\n",
       " 'predict',\n",
       " 'predict_proba',\n",
       " 'random_state',\n",
       " 'sample',\n",
       " 'score',\n",
       " 'score_samples',\n",
       " 'set_params',\n",
       " 'startprob_',\n",
       " 'startprob_prior',\n",
       " 'tol',\n",
       " 'transmat_',\n",
       " 'transmat_prior',\n",
       " 'verbose']"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(modelGMM_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3144.8947375598059"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelGMM_A.score(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3592.8816959576939"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelGHMM_A.score(testA2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelDict = dict()\n",
    "for dataset in trainset:\n",
    "    model = GMMHMM_train(dataset = dataset[1], mix = 6, states = 6, trials = 1,cov = \"diag\",max_iter=2000, randomSeed = 1024)\n",
    "    modelDict[dataset[0]] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth:  ['A', 'B', 'D', 'E', 'F', 'G', 'H']\n",
      "prediction:  ['A', 'B', 'D', 'E', 'F', 'G', 'H']\n",
      "item order in table ['A', 'B', 'D', 'E', 'F', 'G', 'H']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GHMM_evaluate(trainset,modelDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth:  ['A', 'A', 'B', 'D', 'D', 'F', 'F', 'G', 'H', 'H', 'H']\n",
      "prediction:  ['B', 'A', 'H', 'F', 'F', 'F', 'D', 'E', 'F', 'H', 'H']\n",
      "item order in table ['A', 'B', 'D', 'F', 'G', 'H']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 2, 0, 0],\n",
       "       [0, 0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 2]])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GHMM_evaluate(testset,modelDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': GMMHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "     init_params='stmcw', n_components=6, n_iter=1000, n_mix=3,\n",
       "     params='stmcw', random_state=None, startprob_prior=1.0, tol=0.01,\n",
       "     transmat_prior=1.0, verbose=False),\n",
       " 'B': GMMHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "     init_params='stmcw', n_components=6, n_iter=1000, n_mix=3,\n",
       "     params='stmcw', random_state=None, startprob_prior=1.0, tol=0.01,\n",
       "     transmat_prior=1.0, verbose=False),\n",
       " 'D': GMMHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "     init_params='stmcw', n_components=6, n_iter=1000, n_mix=3,\n",
       "     params='stmcw', random_state=None, startprob_prior=1.0, tol=0.01,\n",
       "     transmat_prior=1.0, verbose=False),\n",
       " 'E': GMMHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "     init_params='stmcw', n_components=6, n_iter=1000, n_mix=3,\n",
       "     params='stmcw', random_state=None, startprob_prior=1.0, tol=0.01,\n",
       "     transmat_prior=1.0, verbose=False),\n",
       " 'F': GMMHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "     init_params='stmcw', n_components=6, n_iter=1000, n_mix=3,\n",
       "     params='stmcw', random_state=None, startprob_prior=1.0, tol=0.01,\n",
       "     transmat_prior=1.0, verbose=False),\n",
       " 'G': GMMHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "     init_params='stmcw', n_components=6, n_iter=1000, n_mix=3,\n",
       "     params='stmcw', random_state=None, startprob_prior=1.0, tol=0.01,\n",
       "     transmat_prior=1.0, verbose=False),\n",
       " 'H': GMMHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "     init_params='stmcw', n_components=6, n_iter=1000, n_mix=3,\n",
       "     params='stmcw', random_state=None, startprob_prior=1.0, tol=0.01,\n",
       "     transmat_prior=1.0, verbose=False)}"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testB = np.load(\"project_data/DataSet/BirdBTesting.npy\")\n",
    "testD1 = np.load(\"project_data/DataSet/BirdDTesting1.npy\")\n",
    "testD2 = np.load(\"project_data/DataSet/BirdDTesting2.npy\")\n",
    "testE1 = np.load(\"project_data/DataSet/samples11.npy\")\n",
    "testE2 = np.load(\"project_data/DataSet/samples12.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testset = [('B',testB),('D',testD1),('D',testD2),('E',testE1),('E',testE2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth:  ['B', 'D', 'D', 'E', 'E']\n",
      "prediction:  ['B', 'B', 'B', 'D', 'D']\n",
      "item order in table ['B', 'D', 'E']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [2, 0, 0],\n",
       "       [0, 2, 0]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GHMM_evaluate(testset,modelDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'd']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load in data\n",
    "birdA\n",
    "birdB\n",
    "birdC\n",
    "birdD\n",
    "birdE\n",
    "birdF\n",
    "birdG\n",
    "birdH\n",
    "#train model for each bird\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ModelA_s2 = hmm.GaussianHMM(n_components=2, covariance_type=\"diag\", n_iter=2000).fit(trainA)\n",
    "ModelA_s4 = hmm.GaussianHMM(n_components=4, covariance_type=\"diag\", n_iter=2000).fit(trainA)\n",
    "ModelA_s6 = hmm.GaussianHMM(n_components=6, covariance_type=\"diag\", n_iter=2000).fit(trainA)\n",
    "ModelA_s8 = hmm.GaussianHMM(n_components=8, covariance_type=\"diag\", n_iter=2000).fit(trainA)\n",
    "ModelA_s10 = hmm.GaussianHMM(n_components=10, covariance_type=\"diag\", n_iter=2000).fit(trainA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ModelB_s2 = hmm.GaussianHMM(n_components=2, covariance_type=\"diag\", n_iter=2000).fit(trainB)\n",
    "ModelB_s4 = hmm.GaussianHMM(n_components=4, covariance_type=\"diag\", n_iter=2000).fit(trainB)\n",
    "ModelB_s6 = hmm.GaussianHMM(n_components=6, covariance_type=\"diag\", n_iter=2000).fit(trainB)\n",
    "ModelB_s8 = hmm.GaussianHMM(n_components=8, covariance_type=\"diag\", n_iter=2000).fit(trainB)\n",
    "ModelB_s10 = hmm.GaussianHMM(n_components=10, covariance_type=\"diag\", n_iter=2000).fit(trainB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ModelC_s2 = hmm.GaussianHMM(n_components=2, covariance_type=\"diag\", n_iter=2000).fit(trainC)\n",
    "ModelC_s4 = hmm.GaussianHMM(n_components=4, covariance_type=\"diag\", n_iter=2000).fit(trainC)\n",
    "ModelC_s6 = hmm.GaussianHMM(n_components=6, covariance_type=\"diag\", n_iter=2000).fit(trainC)\n",
    "ModelC_s8 = hmm.GaussianHMM(n_components=8, covariance_type=\"diag\", n_iter=2000).fit(trainC)\n",
    "ModelC_s10 = hmm.GaussianHMM(n_components=10, covariance_type=\"diag\", n_iter=2000).fit(trainC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ModelD_s2 = hmm.GaussianHMM(n_components=2, covariance_type=\"diag\", n_iter=2000).fit(trainD)\n",
    "ModelD_s4 = hmm.GaussianHMM(n_components=4, covariance_type=\"diag\", n_iter=2000).fit(trainD)\n",
    "ModelD_s6 = hmm.GaussianHMM(n_components=6, covariance_type=\"diag\", n_iter=2000).fit(trainD)\n",
    "ModelD_s8 = hmm.GaussianHMM(n_components=8, covariance_type=\"diag\", n_iter=2000).fit(trainD)\n",
    "ModelD_s10 = hmm.GaussianHMM(n_components=10, covariance_type=\"diag\", n_iter=2000).fit(trainD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ModelE_s2 = hmm.GaussianHMM(n_components=2, covariance_type=\"diag\", n_iter=2000).fit(trainE)\n",
    "ModelE_s4 = hmm.GaussianHMM(n_components=4, covariance_type=\"diag\", n_iter=2000).fit(trainE)\n",
    "ModelE_s6 = hmm.GaussianHMM(n_components=6, covariance_type=\"diag\", n_iter=2000).fit(trainE)\n",
    "ModelE_s8 = hmm.GaussianHMM(n_components=8, covariance_type=\"diag\", n_iter=2000).fit(trainE)\n",
    "ModelE_s10 = hmm.GaussianHMM(n_components=10, covariance_type=\"diag\", n_iter=2000).fit(trainE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ModelF_s2 = hmm.GaussianHMM(n_components=2, covariance_type=\"diag\", n_iter=2000).fit(trainF)\n",
    "ModelF_s4 = hmm.GaussianHMM(n_components=4, covariance_type=\"diag\", n_iter=2000).fit(trainF)\n",
    "ModelF_s6 = hmm.GaussianHMM(n_components=6, covariance_type=\"diag\", n_iter=2000).fit(trainF)\n",
    "ModelF_s8 = hmm.GaussianHMM(n_components=8, covariance_type=\"diag\", n_iter=2000).fit(trainF)\n",
    "ModelF_s10 = hmm.GaussianHMM(n_components=10, covariance_type=\"diag\", n_iter=2000).fit(trainF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ModelG_s2 = hmm.GaussianHMM(n_components=2, covariance_type=\"diag\", n_iter=2000).fit(trainG)\n",
    "ModelG_s4 = hmm.GaussianHMM(n_components=4, covariance_type=\"diag\", n_iter=2000).fit(trainG)\n",
    "ModelG_s6 = hmm.GaussianHMM(n_components=6, covariance_type=\"diag\", n_iter=2000).fit(trainG)\n",
    "ModelG_s8 = hmm.GaussianHMM(n_components=8, covariance_type=\"diag\", n_iter=2000).fit(trainG)\n",
    "ModelG_s10 = hmm.GaussianHMM(n_components=10, covariance_type=\"diag\", n_iter=2000).fit(trainG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ModelH_s2 = hmm.GaussianHMM(n_components=2, covariance_type=\"diag\", n_iter=2000).fit(trainH)\n",
    "ModelH_s4 = hmm.GaussianHMM(n_components=4, covariance_type=\"diag\", n_iter=2000).fit(trainH)\n",
    "ModelH_s6 = hmm.GaussianHMM(n_components=6, covariance_type=\"diag\", n_iter=2000).fit(trainH)\n",
    "ModelH_s8 = hmm.GaussianHMM(n_components=8, covariance_type=\"diag\", n_iter=2000).fit(trainH)\n",
    "ModelH_s10 = hmm.GaussianHMM(n_components=10, covariance_type=\"diag\", n_iter=2000).fit(trainH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelDict2 = {'A': ModelA_s2,'B': ModelB_s2,'C': ModelC_s2,'D': ModelD_s2,'E': ModelE_s2,'F':ModelF_s2,'G':ModelG_s2,'H':ModelH_s2}\n",
    "modelDict4 = {'A': ModelA_s4,'B': ModelB_s4,'C': ModelC_s4,'D': ModelD_s4,'E': ModelE_s4,'F':ModelF_s4,'G':ModelG_s4,'H':ModelH_s4}\n",
    "modelDict6 = {'A': ModelA_s6,'B': ModelB_s6,'C': ModelC_s6,'D': ModelD_s6,'E': ModelE_s6,'F':ModelF_s6,'G':ModelG_s6,'H':ModelH_s6}\n",
    "modelDict8 = {'A': ModelA_s8,'B': ModelB_s8,'C': ModelC_s8,'D': ModelD_s8,'E': ModelE_s8,'F':ModelF_s8,'G':ModelG_s8,'H':ModelH_s8}\n",
    "modelDict10 = {'A': ModelA_s10,'B': ModelB_s10,'C': ModelC_s10,'D': ModelD_s10,'E': ModelE_s10,'F':ModelF_s10,'G':ModelG_s10,'H':ModelH_s10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth:  ['A', 'A', 'B', 'C', 'D', 'D', 'E', 'E', 'F', 'F', 'G', 'H', 'H', 'H']\n",
      "prediction:  ['A', 'A', 'B', 'C', 'H', 'H', 'E', 'E', 'H', 'H', 'H', 'H', 'H', 'H']\n",
      "item order in table ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 2],\n",
       "       [0, 0, 0, 0, 2, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 2],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 3]])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GHMM_evaluate(testset,modelDict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianHMM(algorithm='viterbi', covariance_type='diag', covars_prior=0.01,\n",
       "      covars_weight=1, init_params='stmc', means_prior=0, means_weight=0,\n",
       "      min_covar=0.001, n_components=4, n_iter=500, params='stmc',\n",
       "      random_state=None, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "      verbose=False)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelF_s4 = hmm.GaussianHMM(n_components=4, covariance_type=\"diag\", n_iter=500)\n",
    "ModelF_s4.start_prob_ = np.array([0.6, 0.3, 0.1, 0.0])\n",
    "ModelF_s4.fit(trainF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainA = np.load(\"project_data/DataSetWithMultipeak/BirdATraining.npy\")\n",
    "trainB = np.load(\"project_data/DataSetWithMultipeak/BirdBTraining.npy\")\n",
    "trainC = np.load(\"project_data/DataSetWithMultipeak/BirdCTraining.npy\")\n",
    "trainD = np.load(\"project_data/DataSetWithMultipeak/BirdDTraining.npy\")\n",
    "trainE = np.load(\"project_data/DataSetWithMultipeak/BirdETraining.npy\")\n",
    "trainF = np.load(\"project_data/DataSetWithMultipeak/BirdFTraining.npy\")\n",
    "trainG = np.load(\"project_data/DataSetWithMultipeak/BirdGTraining.npy\")\n",
    "trainH = np.load(\"project_data/DataSetWithMultipeak/BirdHTraining.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13604"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainH)#('A',trainA),('B',trainB),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainset =[('C',trainC),('D',trainD),('E',trainE),('F',trainF),('G',trainG),('H',trainH)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelDict = dict()\n",
    "for dataset in trainset:\n",
    "    model = GMMHMM_train(dataset = dataset[1], mix = 5, states = 2, trials = 1,cov = \"diag\",max_iter=1000, randomSeed = 1024)\n",
    "    modelDict[dataset[0]] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testA1 = np.load(\"project_data/DataSetWithMultipeak/TestA09.npy\")\n",
    "testA2 = np.load(\"project_data/DataSetWithMultipeak/TestA10.npy\")\n",
    "testB1 = np.load(\"project_data/DataSetWithMultipeak/TestB05.npy\")\n",
    "testC1 = np.load(\"project_data/DataSetWithMultipeak/TestC06.npy\")\n",
    "testD1 = np.load(\"project_data/DataSetWithMultipeak/TestD09.npy\")\n",
    "testD2 = np.load(\"project_data/DataSetWithMultipeak/TestD10.npy\")\n",
    "testE1 = np.load(\"project_data/DataSetWithMultipeak/TestE11.npy\")\n",
    "testE2 = np.load(\"project_data/DataSetWithMultipeak/TestE12.npy\")\n",
    "testF1 = np.load(\"project_data/DataSetWithMultipeak/TestF09.npy\")\n",
    "testF2 = np.load(\"project_data/DataSetWithMultipeak/TestF10.npy\")\n",
    "testG1 = np.load(\"project_data/DataSetWithMultipeak/TestG07.npy\")\n",
    "testH1 = np.load(\"project_data/DataSetWithMultipeak/TestH16.npy\")\n",
    "testH2 = np.load(\"project_data/DataSetWithMultipeak/TestH17.npy\")\n",
    "testH3 = np.load(\"project_data/DataSetWithMultipeak/TestH18.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testset = [(\"C\",testC1),(\"D\",testD1),(\"D\",testD2),(\"E\",testE1),(\"E\",testE2),(\"F\",testF1), (\"F\",testF2), (\"G\",testG1),(\"H\", testH1),(\"H\", testH2),(\"H\", testH3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#testset = [('F',testF1),('F',testF2),('H',testH1),('H',testH2),('H',testH3)] (\"A\",testA1),(\"A\",testA2),(\"B\",testB1),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth:  ['C', 'D', 'D', 'E', 'E', 'F', 'F', 'G', 'H', 'H', 'H']\n",
      "prediction:  ['G', 'G', 'H', 'E', 'E', 'F', 'C', 'H', 'H', 'G', 'H']\n",
      "item order in table ['C', 'D', 'E', 'F', 'G', 'H']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 2, 0, 0, 0],\n",
       "       [1, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1, 2]])"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GHMM_evaluate(testset,modelDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('C', {'C': 0.21160435396762661, 'E': 0.15268102749216575, 'D': 0.1250347705462401, 'G': 0.21385977992548055, 'F': 0.16681953216834028, 'H': 0.13000053590014679})\n",
      "\n",
      "('D', {'C': 0.13269170024918947, 'E': 0.068848024558604615, 'D': 0.21784088239870045, 'G': 0.19506816460411541, 'F': 0.18556148730190691, 'H': 0.19998974088748311})\n",
      "\n",
      "('E', {'C': 0.84885213033657059, 'E': -0.019444551737001815, 'D': 0.013721217396212694, 'G': 0.11592691989927613, 'F': 0.021106720901140501, 'H': 0.019837563203801992})\n",
      "\n",
      "('F', {'C': 0.14486772094705133, 'E': 0.075871377392778189, 'D': 0.19718517267727484, 'G': 0.19718986029946253, 'F': 0.19228591935041561, 'H': 0.19259994933301758})\n",
      "\n",
      "('G', {'C': 0.16657112685568853, 'E': 0.082684605321982546, 'D': 0.15906771141005235, 'G': 0.23091391625754717, 'F': 0.18792628662212396, 'H': 0.17283635353260549})\n",
      "\n",
      "('H', {'C': 0.11300089398864428, 'E': 0.044272921650065085, 'D': 0.19486673375752261, 'G': 0.21537072544573208, 'F': 0.1776774901818664, 'H': 0.25481123497616964})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for test in trainset:\n",
    "    print inverse_logLike_ratio(test, modelDict)\n",
    "    print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob = dict()\n",
    "\n",
    "for t, model in modelDict.items():\n",
    "    prob[t] = model.predict_proba(testE1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive = [max(x) for x in prob['E']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4007"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testE1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__doc__',\n",
       " '__format__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__module__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_accumulate_sufficient_statistics',\n",
       " '_check',\n",
       " '_compute_log_likelihood',\n",
       " '_compute_posteriors',\n",
       " '_decode_map',\n",
       " '_decode_viterbi',\n",
       " '_do_backward_pass',\n",
       " '_do_forward_pass',\n",
       " '_do_mstep',\n",
       " '_do_viterbi_pass',\n",
       " '_generate_sample_from_state',\n",
       " '_get_param_names',\n",
       " '_init',\n",
       " '_initialize_sufficient_statistics',\n",
       " 'algorithm',\n",
       " 'covariance_type',\n",
       " 'covars_prior',\n",
       " 'decode',\n",
       " 'fit',\n",
       " 'get_params',\n",
       " 'gmms_',\n",
       " 'init_params',\n",
       " 'monitor_',\n",
       " 'n_components',\n",
       " 'n_iter',\n",
       " 'n_mix',\n",
       " 'params',\n",
       " 'predict',\n",
       " 'predict_proba',\n",
       " 'random_state',\n",
       " 'sample',\n",
       " 'score',\n",
       " 'score_samples',\n",
       " 'set_params',\n",
       " 'startprob_',\n",
       " 'startprob_prior',\n",
       " 'tol',\n",
       " 'transmat_',\n",
       " 'transmat_prior',\n",
       " 'verbose']"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(modelDict['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
